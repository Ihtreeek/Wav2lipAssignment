# -*- coding: utf-8 -*-
"""Script.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hkPSvBsYMjZiX8dV3ZpgUcAE47k0LkpU
"""

import os
from IPython.display import Audio, HTML
from IPython.core.display import display
from google.colab import files
import librosa
import soundfile as sf
from base64 import b64encode

# Clone Wav2Lip repository
!git clone https://github.com/Ihtreeek/Wav2lipAssignment

# Download pretrained models
!wget 'https://iiitaphyd-my.sharepoint.com/personal/radrabha_m_research_iiit_ac_in/_layouts/15/download.aspx?share=EdjI7bZlgApMqsVoEUUXpLsBxqXbn5z8VTmoxp55YNDcIA' -O '/content/Wav2Lip/checkpoints/wav2lip_gan.pth'
!wget "https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth" -O "/content/Wav2Lip/face_detection/detection/sfd/s3fd.pth"

# Function to display audio
def displayAudio():
  display(Audio('/content/sample_data/input_audio.wav'))

# Function to display video
def showVideo(path):
  mp4 = open(str(path),'rb').read()
  data_url = "data:video/mp4;base64," + b64encode(mp4).decode()
  return HTML("""
  <video width=700 controls>
        <source src="%s" type="video/mp4">
  </video>
  """ % data_url)

# Remove previous input audio and video
if os.path.isfile('/content/sample_data/input_audio.wav'):
    os.remove('/content/sample_data/input_audio.wav')
if os.path.isfile('/content/sample_data/input_vid.mp4'):
    os.remove('/content/sample_data/input_vid.mp4')

# Upload audio
uploaded = files.upload()
for fn in uploaded.keys():
  print('User uploaded file "{name}" with length {length} bytes'.format(
      name=fn, length=len(uploaded[fn])))
# Consider only the first file
PATH_TO_YOUR_AUDIO = str(list(uploaded.keys())[0])
# Load audio with specified sampling rate
audio, sr = librosa.load(PATH_TO_YOUR_AUDIO, sr=None)
# Save audio with specified sampling rate
sf.write('/content/sample_data/input_audio.wav', audio, sr, format='wav')

# Upload video
uploaded = files.upload()
for fn in uploaded.keys():
  print('User uploaded file "{name}" with length {length} bytes'.format(
      name=fn, length=len(uploaded[fn])))
PATH_TO_YOUR_VIDEO= str(list(uploaded.keys())[0])

#PATH_TO_YOUR_VIDEO='/content/inputvideo.mp4'
# Trim the video (start, end) seconds
start = 0 # change as needed
end = 67 # change as needed
interval = end - start
# Cut the video using FFmpeg
!ffmpeg -y -i {PATH_TO_YOUR_VIDEO} -ss {start} -t {interval} -async 1 /content/sample_data/input_vid.mp4

import ast
import inspect
import astunparse

# Load the original script
with open('/content/Wav2Lip/inference.py', 'r') as file:
    original_script = file.read()

# Parse the script into an abstract syntax tree
tree = ast.parse(original_script)

# Find the function you want to override
for node in ast.walk(tree):
    if isinstance(node, ast.FunctionDef) and node.name == 'function_to_override':
        # This is the function you want to override

        # Create a new function body
        new_body = ast.parse("""
            def datagen(frames, mels):
                img_batch, mel_batch, frame_batch, coords_batch = [], [], [], []

                for i, frame in enumerate(frames):
                    try:
                        # Try to detect the face
                        faces = face_detector.detect_from_image(frame[..., ::-1])
                        if len(faces) == 0:
                            raise ValueError('Face not detected')

                        face = faces[0]
                        frame, coords = face_detector.crop_video(frame, face)

                        frame = cv2.resize(frame, (96, 96))
                        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

                        mel = mels[:, i]
                        if np.isnan(np.sum(mel)):
                            mel = np.zeros([80,])

                        img_batch.append(frame)
                        mel_batch.append(mel)
                        frame_batch.append(frame)
                        coords_batch.append(coords)

                        if len(img_batch) >= args.wav2lip_batch_size:
                            img_batch, mel_batch = np.asarray(img_batch), np.asarray(mel_batch)
                            img_masked = img_batch.copy()
                            img_masked[:, img_masked.shape[1]//2:] = 0

                            img_batch = np.concatenate((img_masked, img_batch), axis=3)

                            yield img_batch, mel_batch, frame_batch, coords_batch
                            img_batch, mel_batch, frame_batch, coords_batch = [], [], [], []

                    except ValueError:
                        # If a face is not detected, skip the frame
                        continue
              if len(img_batch) > 0:
                img_batch, mel_batch = np.asarray(img_batch), np.asarray(mel_batch)

                img_masked = img_batch.copy()
                img_masked[:, args.img_size//2:] = 0

                img_batch = np.concatenate((img_masked, img_batch), axis=3) / 255.
                mel_batch = np.reshape(mel_batch, [len(mel_batch), mel_batch.shape[1], mel_batch.shape[2], 1])

                yield img_batch, mel_batch, frame_batch, coords_batch



        """).body[0].body

        # Replace the original function body with the new body
        node.body = new_body

# Unparse the modified abstract syntax tree back into code
modified_script = astunparse.unparse(tree)

# Save the modified script
with open('/content/Wav2Lip/modified_script.py', 'w') as file:
    file.write(modified_script)

# Run Wav2Lip model
pad_top =  0 # change as needed
pad_bottom =  10 # change as needed
pad_left =  0 # change as needed
pad_right =  0 # change as needed
rescaleFactor =  1 # change as needed
!cd Wav2Lip && python modified_script.py --checkpoint_path checkpoints/wav2lip_gan.pth --face "/content/sample_data/input_vid.mp4" --audio "/content/sample_data/input_audio.wav" --pads $pad_top $pad_bottom $pad_left $pad_right --resize_factor $rescaleFactor

print("Final Video Preview")
print("Download this video from", '/content/Wav2Lip/results/result_voice.mp4')
showVideo('/content/Wav2Lip/results/result_voice.mp4')